{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pubmed_imageDownload.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5anSGyv8f_K"
      },
      "source": [
        "!pip install selenium"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0mIIPb9E88B"
      },
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import requests\n",
        "import shutil"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwMZ-ylUDf8p"
      },
      "source": [
        "class BeautifulScrapper():\n",
        "    def __init__(self, url:str, classid:str, folder:str):\n",
        "        self.url = url\n",
        "        self.classid = classid\n",
        "        self.folder = folder\n",
        "    \n",
        "    def _get_info(self):\n",
        "        image_info = []\n",
        "\n",
        "        response = requests.get(self.url)\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "        aas = soup.find_all(\"a\", class_= self.classid)\n",
        "\n",
        "        for a in aas:\n",
        "            image_tag = a.findChildren(\"img\")\n",
        "            image_info.append((image_tag[0][\"src\"], image_tag[0][\"alt\"]))\n",
        "\n",
        "        return image_info\n",
        "\n",
        "    def _download_images(self, image_info):\n",
        "        response = requests.get(image_info[0], stream=True)\n",
        "        realname = ''.join(e for e in image_info[1] if e.isalnum())\n",
        "        \n",
        "        file = open(self.folder.format(realname), 'wb')\n",
        "        \n",
        "        response.raw.decode_content = True\n",
        "        shutil.copyfileobj(response.raw, file)\n",
        "        del response\n",
        "\n",
        "    def scrape_images(self):\n",
        "        image_info = self._get_info()    \n",
        "        print('Total number of images is', format(len(image_info)))\n",
        "        print()\n",
        "\n",
        "        for i in range(0, len(image_info)):\n",
        "            print('Downloading image #'+str(i+1))\n",
        "            self._download_images(image_info[i])\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M58ApAvwD1pM"
      },
      "source": [
        "img_scrapper = BeautifulScrapper(url = \"https://www.ncbi.nlm.nih.gov/pccompound/?linkname=pubmed_pccompound&from_uid=20033891\", classid='rsltimg', folder='./Images/{}.png')"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIuUby0kENx0",
        "outputId": "6e519aa3-9675-4e9c-f005-d151b32f86ad"
      },
      "source": [
        "img_scrapper.scrape_images()"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images is 5\n",
            "\n",
            "Downloading image #1\n",
            "Downloading image #2\n",
            "Downloading image #3\n",
            "Downloading image #4\n",
            "Downloading image #5\n"
          ]
        }
      ]
    }
  ]
}